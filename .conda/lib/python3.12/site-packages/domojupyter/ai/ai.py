from typing import Optional

import pandas as pd

import domojupyter
from domojupyter.ai.models.ChunkingConfiguration import ChunkingConfiguration
from domojupyter.ai.models.DataSourceSchema import DataSourceSchema
from domojupyter.ai.models.SizeBoundary import SizeBoundary
from domojupyter.ai.models.SummarizationOutputStyle import SummarizationOutputStyle
from domojupyter.ai.models.TextGenerationRequest import TextGenerationRequest, PromptTemplate
from domojupyter.ai.models.TextSummarizationRequest import TextSummarizationRequest
from domojupyter.ai.models.TextToBeastModeRequest import TextToBeastModeRequest
from domojupyter.ai.models.TextToSQLRequest import TextToSQLRequest
from domojupyter.domo import Domo, DomoDataflowAuthentication, DomoHubAuthentication, DomoResourceTokenAuthentication
from domojupyter.jupyterhub import Jupyterhub
from domojupyter.ai.models.TextAIResponse import TextAIResponse
import os

__all__ = ['text_to_sql', 'generate_text', 'text_to_beast_mode', 'summarize']

jupyterhub_services_url = os.getenv('JUPYTERHUB_SERVICES_URL', None)
jupyterhub_api_token = os.getenv('JUPYTERHUB_API_TOKEN', None)
domo_hostname = os.getenv('DOMO_HOSTNAME', None)
domo_resource_token = os.getenv('DOMO_RESOURCE_TOKEN')
workspace_id = os.getenv('DOMO_WORKSPACE_ID', None)
workspace_session_id = os.getenv('DOMO_WORKSPACE_SESSION_ID', None)

if domo_resource_token is None:
    _jupyterhub = Jupyterhub(jupyterhub_services_url, jupyterhub_api_token, workspace_id, workspace_session_id)
    _domo = Domo(domo_hostname, DomoHubAuthentication(_jupyterhub), workspace_id)
else:
    _resource_token_domo = Domo(domo_hostname, DomoResourceTokenAuthentication(domo_resource_token), workspace_id)
    _domo = Domo(domo_hostname, DomoDataflowAuthentication(_resource_token_domo, workspace_id), workspace_id)


def text_to_sql(input_str: str,
                prompt_template: Optional[PromptTemplate] = None,
                data_source_schemas: Optional[list[DataSourceSchema]] = None,
                parameters: Optional[dict[str, str]] = None,
                model: Optional[str] = None,
                model_configuration: Optional[dict[str, object]] = None,
                workspace_data_source_alias: Optional[str] = None,
                dataframe: Optional[pd.DataFrame] = None
                ):
    """
    Convert text to SQL

    Parameters:
        input_str (str): input string
        data_source_schemas (list[DataSourceSchema]): list of data source schemas
        prompt_template (PromptTemplate): prompt template
        parameters (dict[str, str]): parameters
        model (str): model name
        model_configuration (dict[str, object]): model configuration
        workspace_data_source_alias (str): data source schema alias associated to workspace
        dataframe (pd.DataFrame): Pandas dataframe

    Returns:
        text_ai_response: TextAiResponse
    """
    if workspace_data_source_alias is not None:
        data_source_schemas = [
            DataSourceSchema.from_optional_list(
                domojupyter.io.get_schema_from_datasource(workspace_data_source_alias).get('schema'),
                workspace_data_source_alias)]
    elif dataframe is not None:
        schema = domojupyter.io.get_schema_from_dataframe(dataframe)
        data_source_schemas = [
            DataSourceSchema.from_optional_list(
                schema,
                dataframe.name)]
    text_to_sql_request = TextToSQLRequest(input_str, data_source_schemas, prompt_template, parameters, model,
                                           model_configuration)
    sql_response = _jupyterhub.text_to_sql(text_to_sql_request.to_json())
    text_ai_response = TextAIResponse(sql_response['prompt'], sql_response['choices'])
    return text_ai_response


def generate_text(input_str: str,
                  prompt_template: Optional[PromptTemplate] = None,
                  parameters: Optional[dict[str, str]] = None,
                  model: Optional[str] = None,
                  model_configuration: Optional[dict[str, object]] = None):
    """
    Generate text from String input

    Parameters:
        input_str (str): input string
        prompt_template (PromptTemplate): prompt template
        parameters (dict[str, str]): parameters
        model (str): model name
        model_configuration (dict[str, object]): model configuration

    Returns:
        response: generated text
    """
    text_generation_request = TextGenerationRequest(input_str, prompt_template, parameters, model,
                                                    model_configuration)
    text_response = _jupyterhub.generate_text(text_generation_request.to_json())
    text_ai_response = TextAIResponse(text_response['prompt'], text_response['choices'])
    return text_ai_response


def text_to_beast_mode(input_str: str,
                       prompt_template: Optional[PromptTemplate] = None,
                       data_source_schema: Optional[DataSourceSchema] = None,
                       parameters: Optional[dict[str, str]] = None,
                       model: Optional[str] = None,
                       model_configuration: Optional[dict[str, object]] = None):
    """
    Convert text to Beastmode

    Parameters:
        input_str (str): input string
        data_source_schema (DataSourceSchema): data source schema
        prompt_template (PromptTemplate): prompt
        parameters (dict[str, str]): parameters
        model (str): model name
        model_configuration (dict[str, object]): model configuration

    Returns:
        sql: SQL string
    """
    text_to_beast_mode_request = TextToBeastModeRequest(input_str, data_source_schema, prompt_template, parameters,
                                                        model, model_configuration)
    beast_mode_response = _jupyterhub.text_to_beast_mode(text_to_beast_mode_request.to_json())
    text_ai_response = TextAIResponse(beast_mode_response['prompt'], beast_mode_response['choices'])
    return text_ai_response


def summarize(input_str: str,
              prompt_template: Optional[PromptTemplate] = None,
              parameters: Optional[dict[str, str]] = None,
              model: Optional[str] = None,
              model_configuration: Optional[dict[str, object]] = None,
              system: Optional[str] = None,
              chunking_configuration: Optional[ChunkingConfiguration] = None,
              output_style: Optional[SummarizationOutputStyle] = None,
              output_word_length: Optional[SizeBoundary] = None):
    """
    Summarize text

    Parameters:
        input_str (str): Text information to be summarized. This attribute is mandatory.
        prompt_template (PromptTemplate): prompt template
        parameters (dict): A dictionary containing parameter-name and its corresponding value.
            It's used for replacing the placeholders in the PromptTemplate.
        model (str): Name/id of the language model to be used for summarization
        model_configuration (dict): A dictionary with custom configuration parameters for a selected language model.
        system (str): System or the type of AI being used for text summarization.
        chunking_configuration (ChunkingConfiguration): Configuration for dividing the given text into smaller parts or chunks.
        output_style (SummarizationOutputStyle): Determines the design, structuring and organization of the summarization's output.
        output_word_length (SizeBoundary): Defines a size boundary to limit the length of the output summary, based on number of words.

    Returns:
        response: summarized text
    """
    text_summarization_request = TextSummarizationRequest(input_str, prompt_template, parameters, model,
                                                          model_configuration, system, chunking_configuration,
                                                          output_style, output_word_length)
    str_request = text_summarization_request.to_json()
    text_response = _jupyterhub.summarize(text_summarization_request.to_json())
    text_ai_response = TextAIResponse(text_response['prompt'], text_response['choices'])
    return text_ai_response
